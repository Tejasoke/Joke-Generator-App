{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btNWxCLHAyul",
        "outputId": "34179bdd-3520-41a8-f2d6-eca3dce7b9fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data:\n",
            "    ID                                               Joke\n",
            "0   1  [me narrating a documentary about narrators] \"...\n",
            "1   2  Telling my daughter garlic is good for you. Go...\n",
            "2   3  I've been going through a really rough period ...\n",
            "3   4  If I could have dinner with anyone, dead or al...\n",
            "4   5     Two guys walk into a bar. The third guy ducks.\n",
            "\n",
            "Column Names: Index(['ID', 'Joke'], dtype='object')\n",
            "\n",
            "Cleaned and Tokenized Data:\n",
            "                                    cleaned_joke_text  \\\n",
            "0  me narrating a documentary about narrators i c...   \n",
            "1  telling my daughter garlic is good for you goo...   \n",
            "2  ive been going through a really rough period a...   \n",
            "3  if i could have dinner with anyone dead or ali...   \n",
            "4       two guys walk into a bar the third guy ducks   \n",
            "\n",
            "                                      tokenized_joke  \n",
            "0  [me, narrating, a, documentary, about, narrato...  \n",
            "1  [telling, my, daughter, garlic, is, good, for,...  \n",
            "2  [ive, been, going, through, a, really, rough, ...  \n",
            "3  [if, i, could, have, dinner, with, anyone, dea...  \n",
            "4  [two, guys, walk, into, a, bar, the, third, gu...  \n",
            "\n",
            "Padded Sequences:\n",
            "                                       tokenized_joke  \\\n",
            "0  [me, narrating, a, documentary, about, narrato...   \n",
            "1  [telling, my, daughter, garlic, is, good, for,...   \n",
            "2  [ive, been, going, through, a, really, rough, ...   \n",
            "3  [if, i, could, have, dinner, with, anyone, dea...   \n",
            "4  [two, guys, walk, into, a, bar, the, third, gu...   \n",
            "\n",
            "                                         padded_joke  \n",
            "0  [2, 9, 1, 11, 5, 9, 1, 4, 4, 4, 6, 6, 3, 2, 7,...  \n",
            "1  [7, 2, 8, 6, 2, 4, 3, 3, 4, 6, 6, 3, 5, 5, 9, ...  \n",
            "2  [3, 4, 5, 7, 1, 6, 5, 6, 2, 4, 4, 4, 3, 2, 3, ...  \n",
            "3  [2, 1, 5, 4, 6, 4, 6, 4, 2, 5, 1, 5, 6, 5, 2, ...  \n",
            "4  [3, 4, 4, 4, 1, 3, 3, 5, 3, 5, 0, 0, 0, 0, 0, ...  \n",
            "\n",
            "Preprocessed data saved to preprocessed_jokes.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# Download NLTK data (if not already installed)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/shortjokes.csv\"  # Replace with your file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Set a maximum of 20000 rows\n",
        "max_rows = 2000\n",
        "if len(df) > max_rows:\n",
        "    df = df.iloc[:max_rows]  # Keep only the first 200 rows\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(\"Original Data:\\n\", df.head())\n",
        "\n",
        "# Inspect the column names (assuming the jokes are in a column named 'joke_text')\n",
        "print(\"\\nColumn Names:\", df.columns)\n",
        "\n",
        "# Drop any rows with missing jokes\n",
        "df.dropna(subset=['Joke'], inplace=True)\n",
        "\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\n', ' ', text)  # Remove newlines\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation and special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the jokes\n",
        "df['cleaned_joke_text'] = df['Joke'].apply(clean_text)\n",
        "\n",
        "# Tokenize the jokes\n",
        "df['tokenized_joke'] = df['cleaned_joke_text'].apply(word_tokenize)\n",
        "\n",
        "# Display the cleaned and tokenized jokes\n",
        "print(\"\\nCleaned and Tokenized Data:\\n\", df[['cleaned_joke_text', 'tokenized_joke']].head())\n",
        "\n",
        "# Set the maximum sequence length for padding/truncation\n",
        "max_length = 20\n",
        "\n",
        "# Pad the sequences (tokenized jokes)\n",
        "df['padded_joke'] = pad_sequences(\n",
        "    df['tokenized_joke'].apply(lambda x: [len(token) for token in x]),  # Convert tokens to integers\n",
        "    maxlen=max_length,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ").tolist()\n",
        "\n",
        "# Display the padded sequences\n",
        "print(\"\\nPadded Sequences:\\n\", df[['tokenized_joke', 'padded_joke']].head())\n",
        "\n",
        "# Save the preprocessed data to a new CSV file (optional)\n",
        "output_file_path = \"preprocessed_jokes.csv\"\n",
        "df.to_csv(output_file_path, index=False)\n",
        "print(f\"\\nPreprocessed data saved to {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjaDcsbjLp8d",
        "outputId": "53ec4b64-2360-42b6-e9ce-e158303ba69f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bag of Words Matrix:\n",
            " [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Feature Names: ['01' '010' '045' ... 'zune' 'zurich' 'zzzz']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "# Assuming the CSV has a column named 'text' containing the text data\n",
        "df = pd.read_csv('/Users/tejasoke/Downloads/joke_generator_app/preprocessed_jokes.csv')\n",
        "\n",
        "# Extract the text data from the DataFrame\n",
        "texts = df['cleaned_joke_text'].astype(str).tolist()\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the text data to create the BoW representation\n",
        "bow_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Display the BoW matrix\n",
        "print(\"Bag of Words Matrix:\\n\", bow_matrix.toarray())\n",
        "\n",
        "# Display the feature names (i.e., the words)\n",
        "print(\"\\nFeature Names:\", vectorizer.get_feature_names_out())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779,
          "referenced_widgets": [
            "3015e4b21a5842a4ab346dc9fb9ac711",
            "68ce017281334f70ba5e860fe544da2d",
            "0a8d8018412c45e0829cbe660f3e3d28",
            "650d605aef6e4950b84a9374c222ea9b",
            "8b4d80a5a58846518fe73c2e85e94063",
            "9cf027ae95d44ed0aa9e4483f32ba8a0",
            "cb3d27c5e6f14a5b8402578e3ccf5a15",
            "8c243ec362ff47fb903af1072b9418ec",
            "94f0b7bcbc004b6d9f9bfda40735a836",
            "d8380d67158f4806bbec7c9d86b33f3c",
            "72d12e77799849e38b62678f0c16cd4b"
          ]
        },
        "id": "7T90KaPFPBAs",
        "outputId": "ecc468bc-952b-4670-a33a-a39576c060a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3015e4b21a5842a4ab346dc9fb9ac711",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 03:33, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.751000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete. Model and tokenizer saved.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load the jokes from the CSV file\n",
        "df = pd.read_csv('/content/preprocessed_jokes.csv')  # Ensure the file path is correct\n",
        "\n",
        "# Convert the cleaned jokes column to a list\n",
        "jokes_list = df['cleaned_joke_text'].tolist()\n",
        "\n",
        "# Create a Dataset object\n",
        "dataset = Dataset.from_dict({\"text\": jokes_list})\n",
        "\n",
        "# Set padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Use the end-of-sequence token as the padding token\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    tokenized = tokenizer(examples['text'], truncation=True, padding=\"max_length\", max_length=50)\n",
        "    tokenized['labels'] = tokenized['input_ids'].copy()  # Set labels to input_ids\n",
        "    return tokenized\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Include original tokenized_joke if needed for reference\n",
        "df['tokenized_joke'] = df['tokenized_joke'].apply(eval)  # Assuming tokenized_joke is stored as a string representation of a list\n",
        "tokenized_dataset = tokenized_dataset.add_column(\"original_tokenized_joke\", df['tokenized_joke'].tolist())\n",
        "\n",
        "# Ensure the tokenized dataset is in the correct format\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'original_tokenized_joke'])\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    save_steps=500,\n",
        "    max_steps=1000,  # Set the maximum number of training steps\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Save the model and tokenizer using Hugging Face's method\n",
        "model.save_pretrained('./fine-tuned-gpt2')\n",
        "tokenizer.save_pretrained('./fine-tuned-gpt2')\n",
        "\n",
        "print(\"Training complete. Model and tokenizer saved.\")\n",
        "\n",
        "# Save additional components or settings as needed\n",
        "# You can save any other objects, such as training arguments or additional metadata\n",
        "joblib.dump(training_args, 'training_args.pkl')\n",
        "\n",
        "# If you want to save model configuration or state separately, you can do that as well\n",
        "model_config = model.config.to_dict()  # Convert model config to a dictionary\n",
        "joblib.dump(model_config, 'model_config.pkl')\n",
        "# Specify the path for loading later\n",
        "config_path = 'model_config.pkl'  # This will be the path you will use later to load the configuration\n",
        "# Save the model using joblib (not typical, but if needed)\n",
        "# This will not save the model weights properly; use Hugging Face's method instead\n",
        "# joblib.dump(model, 'trained_model.pkl')  # Commented out as it's not recommended\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a8d8018412c45e0829cbe660f3e3d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c243ec362ff47fb903af1072b9418ec",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94f0b7bcbc004b6d9f9bfda40735a836",
            "value": 20000
          }
        },
        "3015e4b21a5842a4ab346dc9fb9ac711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68ce017281334f70ba5e860fe544da2d",
              "IPY_MODEL_0a8d8018412c45e0829cbe660f3e3d28",
              "IPY_MODEL_650d605aef6e4950b84a9374c222ea9b"
            ],
            "layout": "IPY_MODEL_8b4d80a5a58846518fe73c2e85e94063"
          }
        },
        "650d605aef6e4950b84a9374c222ea9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8380d67158f4806bbec7c9d86b33f3c",
            "placeholder": "​",
            "style": "IPY_MODEL_72d12e77799849e38b62678f0c16cd4b",
            "value": " 20000/20000 [00:08&lt;00:00, 5061.38 examples/s]"
          }
        },
        "68ce017281334f70ba5e860fe544da2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cf027ae95d44ed0aa9e4483f32ba8a0",
            "placeholder": "​",
            "style": "IPY_MODEL_cb3d27c5e6f14a5b8402578e3ccf5a15",
            "value": "Map: 100%"
          }
        },
        "72d12e77799849e38b62678f0c16cd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4d80a5a58846518fe73c2e85e94063": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c243ec362ff47fb903af1072b9418ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f0b7bcbc004b6d9f9bfda40735a836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cf027ae95d44ed0aa9e4483f32ba8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb3d27c5e6f14a5b8402578e3ccf5a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8380d67158f4806bbec7c9d86b33f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
